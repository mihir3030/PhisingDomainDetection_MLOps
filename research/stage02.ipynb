{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataPreprocessConfig:\n",
    "    root_dir: Path\n",
    "    load_file_path: Path\n",
    "    local_file: Path\n",
    "    params_select_columns: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PhishingDomainDetection.constants import CONFIG_FILE_PATH, PARAMS_FILE_APTH\n",
    "from PhishingDomainDetection.utils import read_yaml_file, create_directories\n",
    "from PhishingDomainDetection.entity import DataIngestionConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhishingDomainDetection.entity.config_entity.DataIngestionConfig"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataIngestionConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_file_path=CONFIG_FILE_PATH, params_file_path=PARAMS_FILE_APTH):\n",
    "        self.config = read_yaml_file(config_file_path)\n",
    "        self.params = read_yaml_file(params_file_path)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_load_for_preprocess(self):\n",
    "        self.data_load_config = self.config.data_ingestion\n",
    "        self.root_dir = self.data_load_config.root_dir\n",
    "        self.file_dir = self.data_load_config.local_file\n",
    "        self.file_path = os.path.join(self.root_dir, self.file_dir)\n",
    "        return self.file_path\n",
    "       \n",
    "\n",
    "    def get_data_preprocess_config(self) -> DataPreprocessConfig:\n",
    "        data_preprocessing = self.config.data_preprocessing\n",
    "        dataset_load = os.path.join(self.config.data_ingestion.root_dir, \"data.csv\") \n",
    "        \n",
    "\n",
    "\n",
    "        create_directories([data_preprocessing.root_dir])\n",
    "\n",
    "        data_preprocess_config = DataPreprocessConfig(\n",
    "            root_dir=Path(data_preprocessing.root_dir),\n",
    "            load_file_path=Path(dataset_load),\n",
    "            local_file=Path(data_preprocessing.local_file),\n",
    "            params_select_columns=self.params.select_columns\n",
    "        )\n",
    "\n",
    "        return data_preprocess_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AA:\n",
    "    def hello(self):\n",
    "        self.hii = \"kkk\"\n",
    "        print(self.hii)\n",
    "    def hello2(self):\n",
    "        self.hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kkk\n"
     ]
    }
   ],
   "source": [
    "cc = AA()\n",
    "cc.hello2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split      \n",
    "from sklearn.preprocessing import StandardScaler  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocess:\n",
    "    def __init__(self, config: DataPreprocessConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def data_load(self):\n",
    "        data_path = self.config.load_file_path\n",
    "        data = pd.read_csv(data_path)\n",
    "        select_columns = self.config.params_select_columns\n",
    "        self.df = data[select_columns]\n",
    "    \n",
    "    def handling_missing_value(self):\n",
    "        # we have already done research on missing values. you can refer research/preprocessing.ipynb\n",
    "        # delete params_length because it's having 91% missing values\n",
    "        self.df = self.df.drop('params_length', axis=1)\n",
    "\n",
    "        # fill missing values with median\n",
    "        self.df = self.df.replace(-1, np.nan)\n",
    "        self.df = self.df.fillna(self.df.median())\n",
    "\n",
    "    def handling_imbalanced_data(self):\n",
    "        sm = SMOTE(random_state = 33)\n",
    "        self.df_new, df_phishing_new = sm.fit_resample(self.df.drop('phishing', axis=1), self.df.phishing)\n",
    "        self.df_new['phishing'] = df_phishing_new\n",
    "\n",
    "        \n",
    "    def sacling_data(self):\n",
    "        scaler = StandardScaler()\n",
    "        self.df_scaled = pd.DataFrame(scaler.fit_transform(self.df_new.drop('phishing', axis=1)),columns = self.df.columns[:-1])\n",
    "        self.df_scaled['phishing'] = self.df_new.phishing\n",
    "\n",
    "    def saving_preprocessing_data(self):\n",
    "        data_preprocessing_root_dir = self.config.root_dir\n",
    "        local_file_dir = self.config.local_file\n",
    "\n",
    "        raw_local_dir_path = os.path.join(data_preprocessing_root_dir, local_file_dir)\n",
    "\n",
    "        self.df_scaled.to_csv(raw_local_dir_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-04 20:17:48,691: INFO common]: yaml file configs\\config.yaml load  successfully\n",
      "[2023-02-04 20:17:48,699: INFO common]: yaml file params.yaml load  successfully\n",
      "[2023-02-04 20:17:48,701: INFO common]: created directory at artifacts\n",
      "[2023-02-04 20:17:48,703: INFO common]: created directory at artifacts/data_preprocessing\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "data_preprocess_config = config.get_data_preprocess_config()\n",
    "data_preprocess = DataPreprocess(config=data_preprocess_config)\n",
    "data_preprocess.data_load()\n",
    "data_preprocess.handling_missing_value()\n",
    "data_preprocess.handling_imbalanced_data()\n",
    "data_preprocess.sacling_data()\n",
    "data_preprocess.saving_preprocessing_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22ff71f9cfc326748efd7a9104604504f4396b9e94072460122b9aa830a0da70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
